<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta name="generator" content="Hugo 0.87.0" />
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Word Embedding </title>

  
  <meta name="description" content="This article explains the word embedding functionalities in IndicLP"> 
  
  
  
  
  

  

  <meta name="author" content="Aakash and Adityan">


  <meta property="og:title" content="Word Embedding" />
<meta property="og:description" content="This article explains the word embedding functionalities in IndicLP" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://aakash-ez.github.io/indicLP-docs/blog/word-embedding/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2021-10-29T00:00:00+01:00" />
<meta property="article:modified_time" content="2021-10-29T00:00:00+01:00" />


  




  
  
  
  
  

  <link rel="canonical" href="https://aakash-ez.github.io/indicLP-docs/blog/word-embedding/">  

  <link rel="shortcut icon" type="image/png" href="/indicLP-docs/img/favicons/favicon.png">


  <link href="/indicLP-docs/css/font.css" rel="stylesheet" type="text/css">
  <link href="/indicLP-docs/css/kube.min.css" rel="stylesheet" type="text/css">
  <link href="/indicLP-docs/css/kube.legenda.css" rel="stylesheet" type="text/css">
  <link href="/indicLP-docs/css/highlight.css" rel="stylesheet" type="text/css">
  <link href="/indicLP-docs/css/main.css" rel="stylesheet" type="text/css">
  

 <link href="/indicLP-docs/css/custom.css" rel="stylesheet" type="text/css">

  <script src="/indicLP-docs/js/jquery-2.1.4.min.js" type="text/javascript">
  </script>

  <script type="text/javascript" src="/indicLP-docs/js/tocbot.min.js"></script>
</head>


<body class="page-kube">
  <header> <div class="show-sm">
    <div id="nav-toggle-box">
      <div id="nav-toggle-brand">
        <a href="/">indicLP</a>
      </div><a data-component="toggleme" data-target="#top" href="#" id="nav-toggle"><i class="kube-menu"></i></a>
    </div>
  </div>
  <div class="hide-sm" id="top">
    <div id="top-brand">
      <a href="/indicLP-docs" title="home">indicLP</a>
    </div>
    <nav id="top-nav-main">
      <ul>
       
       
    <li><a href="/indicLP-docs/blog/" >Blog</a></li>
    
    <li><a href="/indicLP-docs/docs/" >Docs</a></li>
    
    <li><a href="/indicLP-docs/faq/" >Faq</a></li>
    
      </ul>
    </nav>
    <nav id="top-nav-extra"> 
      <ul>
          
      </ul>
    </nav>
  </div>
 </header>
  <main>
<div class="push-center" itemscope itemtype="http://schema.org/BlogPosting">
  <meta itemprop="name" content="Word Embedding">
<meta itemprop="description" content="This article explains the word embedding functionalities in IndicLP"><meta itemprop="datePublished" content="2021-10-29T00:00:00+01:00" />
<meta itemprop="dateModified" content="2021-10-29T00:00:00+01:00" />
<meta itemprop="wordCount" content="351">
<meta itemprop="keywords" content="" />
  <div id="hero">
    <h1 itemprop="headline">Word Embedding</h1>
    
    <blockquote itemprop="description">This article explains the word embedding functionalities in IndicLP</blockquote>
    
    <time class="post-time"><span class="icon">
  <i class="fa fa-clock-o" aria-hidden="true"></i>
</span>
<span>2 minute read</span>
<span class="icon">
 <i class="fa fa-pencil" aria-hidden="true"></i>
</span>

  Published: <time datetime="2021-10-29T00:00:00&#43;01:00">29 Oct, 2021</time>

</time>
  </div>
  <div id="post-box">
    <div id="post" itemprop="articleBody"><h2 id="getting-started">Getting Started</h2>
<p>Word Embedding has become one of the most crucial aspect of NLP tasks, as it helps in representing the meaning of words in a way computer can understand. Let us first consider the definition of Word Embedding, provided by Stanford&rsquo;s RCpedia:</p>
<blockquote>
<p>Word Embeddings are a method to translate a string of text into an N-dimensional vector of real numbers. Many computational methods are not capable of accepting text as input. This is one method of transforming text into a number space that can be used in various computational methods.</p>
</blockquote>
<p>In this article we&rsquo;ll be trying to achieve exactly that, embedding words as a n-dimensional vector, using indicLP library.</p>
<h2 id="using-word-embedding">Using Word Embedding</h2>
<p>To get us started, we first need to import the Embedding class from IndicLP, preprocessing submodule, as show below.</p>


<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">from</span> <span style="color: #0e84b5; font-weight: bold">indicLP.preprocessing</span> <span style="color: #008800; font-weight: bold">import</span> Embedding
</pre></div>
<br>


<p>Once we have imported the class, we must define an instance of the class with the required language. IndicLP&rsquo;s embedder is made using Gensim library&rsquo;s word2vec model, a standard model used in NLP tasks.</p>


<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">embedder <span style="color: #333333">=</span> Embedding(lang<span style="color: #333333">=</span><span style="background-color: #fff0f0">&quot;ta&quot;</span>)
</pre></div><br>


<p>Now we can use this embedder object to get the associated numpy vector for various words, as required in the task. Here we are going to use the get_vector method on a hardcoded string to showcase its usecase.</p>


<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">word <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&quot;உயிர்&quot;</span>

<span style="color: #008800; font-weight: bold">print</span>(embedder<span style="color: #333333">.</span>get_vector(word)<span style="color: #333333">.</span>shape)
</pre></div><br>


<p>The above code will give the output as (300,) which is the shape of the numpy array returned when using to builtin word embedding models.</p>
<h2 id="getting-the-top-10-closest-words">Getting the top 10 closest words</h2>
<p>Besides providing the vector for processing, indicLP also provides a function to print the top <em>n</em> words (stems to be more accurate) closely associated with the word provided. get_closest function of Embedding class achieves this. To use this function you need to provide two input argument, the word and the number of words needed (default value is 10), as shown below.</p>


<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">word <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&quot;உயிர்&quot;</span>
<span style="color: #008800; font-weight: bold">print</span>(embedder<span style="color: #333333">.</span>get_closest(word))
</pre></div><br>


<p>This will give us a list of tuples, containing the stem of the found word and score associated with it.</p>


<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">[(<span style="background-color: #fff0f0">&#39;உடலை&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.8038842082023621</span>), (<span style="background-color: #fff0f0">&#39;மனிதர்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7657704949378967</span>), (<span style="background-color: #fff0f0">&#39;வாழ&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7598057985305786</span>), (<span style="background-color: #fff0f0">&#39;மனம்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7563427686691284</span>), (<span style="background-color: #fff0f0">&#39;துன்பம்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7538397312164307</span>), (<span style="background-color: #fff0f0">&#39;தீய&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7489129900932312</span>), (<span style="background-color: #fff0f0">&#39;உள்ளம்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7443488240242004</span>), (<span style="background-color: #fff0f0">&#39;தாம்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7373127937316895</span>), (<span style="background-color: #fff0f0">&#39;மனிதன்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7366601824760437</span>), (<span style="background-color: #fff0f0">&#39;நம்&#39;</span>, <span style="color: #6600EE; font-weight: bold">0.7319730520248413</span>)]
</pre></div>


</div>


  </div>
  </div>
  </main>
  <footer>   <footer id="footer">
    <nav>
      <ul>
        <li><span>indicLP</span></li>
        <li>
          <a href="/indicLP-docs/blog/">Blog</a>
        </li>
          <li>
          <a href="/indicLP-docs/docs/">Docs</a>
        </li>
        <li>
          <a href="https://twitter.com/">Give a shout-out on Twitter!</a>
        </li>
      </ul>
    </nav>
    <p>&copy; Licence MIT.</p>
  </footer> </footer>


  <script src="/indicLP-docs/js/kube.js" type="text/javascript">
  </script>
  <script src="/indicLP-docs/js/kube.legenda.js" type="text/javascript">
  </script>
  <script src="/indicLP-docs/js/main.js" type="text/javascript">
  </script>
</body>

</html>
